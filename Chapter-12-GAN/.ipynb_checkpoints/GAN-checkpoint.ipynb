{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../Chapter-7-Convolutional-Neural-Network/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../Chapter-7-Convolutional-Neural-Network/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../Chapter-7-Convolutional-Neural-Network/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../Chapter-7-Convolutional-Neural-Network/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"../Chapter-7-Convolutional-Neural-Network/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x27de9e11f98>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfxAUsQPJEX8QFL/B2SbkJchAZQuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27de9c16f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mnist.train.images[12].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z,reuse=None):\n",
    "    # z:random noise\n",
    "    \n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        # variable_scope: choose subsets of parameters\n",
    "        hidden1 = tf.layers.dense(inputs=z,units=128)\n",
    "        \n",
    "        # use leaky relu as activate function\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        output = tf.layers.dense(hidden2,units=784,activation=tf.nn.tanh)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(X,reuse=None):\n",
    "    # z:random noise\n",
    "    \n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        # variable_scope: choose subsets of parameters\n",
    "        hidden1 = tf.layers.dense(inputs=X,units=128)\n",
    "        \n",
    "        # use leaky relu as activate function\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs=hidden1,units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1) # know real or fake img\n",
    "        output =tf.sigmoid(logits)\n",
    "        \n",
    "        return output,logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "real_images = tf.placeholder(tf.float32,shape=[None,784])\n",
    "z = tf.placeholder(tf.float32,shape=[None,100]) # 100 random points\n",
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real discriminator to train on real images\n",
    "D_output_real, D_logits_real = discriminator(real_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fake discriminator to train on fake images\n",
    "D_output_fake, D_logits_fake = discriminator(G,reuse=True)  # we need to reuse the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOSSES\n",
    "\n",
    "def loss_func(logits_in,labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in,labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss trained on real data, all the labels are true, labels has the same shape as logits, 0.9 is a smoothing factor\n",
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real)*0.9)\n",
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss of generator\n",
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Two Optimizer : One for generator, One for discriminator\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate).minimize(D_loss,var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate).minimize(G_loss,var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dis/dense/kernel:0' shape=(784, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/kernel:0' shape=(128, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        num_batches = mnist.train.num_examples // batch_size\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            \n",
    "            batch = mnist.train.next_batch(batch_size)\n",
    "            \n",
    "            batch_images = batch[0].reshape((barch_size,784)) # 0 is feature 1 is number label\n",
    "            batch_images = barch_images * 2 - 1 # make sense for tanh\n",
    "            \n",
    "            batch_z = np.random.uniform(-1,1,size = (batch_size,100))\n",
    "            \n",
    "            # not interested in the model but the generated images\n",
    "            _ = sess.run(D_trainer,feed_dict={real_images:batch_images,z:batch_z})\n",
    "            _ = sess.run(G_trainer,feed_dict={z:batch_z})\n",
    "            \n",
    "        print(\"ON EPOCH {}\".format(epoch))\n",
    "        \n",
    "        # generate one sample from generator\n",
    "        # initilization\n",
    "        sample_z = np.random.uniform(-1,1,size(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        samples.append(gen_sample)\n",
    "            \n",
    "            \n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
